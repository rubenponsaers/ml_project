{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06c3a52",
   "metadata": {},
   "source": [
    "# Task 2: 'Learning & Dynamics' in OpenSpiel\n",
    "Documentation: https://github.com/deepmind/open_spiel/blob/master/open_spiel/matrix_game.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a04fc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from part2_utils import *\n",
    "\n",
    "import numpy as np\n",
    "import pyspiel\n",
    "\n",
    "from open_spiel.python.algorithms import random_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502ce80",
   "metadata": {},
   "source": [
    "### Biased Rock-Paper-Scissors\n",
    "-> zero-sum game\n",
    "\n",
    "#### Initialization of Biased RPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a64bc545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------GAME---------\n",
      "biased_rps()\n",
      "--------------------\n",
      "\n",
      "-------STATE--------\n",
      "Terminal? false\n",
      "Row actions: P1_Rock P1_Paper P1_Scissors \n",
      "Col actions: P2_Rock P2_Paper P2_Scissors \n",
      "Utility matrix:\n",
      "0,0 -0.25,0.25 0.5,-0.5 \n",
      "0.25,-0.25 0,0 -0.05,0.05 \n",
      "-0.5,0.5 0.05,-0.05 0,0 \n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#configure game\n",
    "row_player_utils = [[0, -0.25, 0.5], [0.25, 0, -0.05], [-0.5, 0.05, 0]]\n",
    "col_player_utils = [[0, 0.25, -0.5], [-0.25, 0, 0.05], [0.5, -0.05, 0]]\n",
    "short_name = 'biased_rps'\n",
    "long_name = 'Biased Rock-Paper-Scissors'\n",
    "row_names, col_names = ['P1_Rock', 'P1_Paper', 'P1_Scissors'], ['P2_Rock', 'P2_Paper', 'P2_Scissors']\n",
    "\n",
    "#initialize game\n",
    "biased_rps_game = pyspiel.create_matrix_game(short_name, long_name, row_names, col_names, row_player_utils, col_player_utils)\n",
    "\n",
    "#display game\n",
    "print('-------GAME---------'+'\\n'+str(biased_rps_game))\n",
    "print('--------------------'+'\\n')\n",
    "\n",
    "#initialize first state of game\n",
    "state = biased_rps_game.new_initial_state()\n",
    "\n",
    "#display state\n",
    "print('-------STATE--------'+'\\n'+str(state))\n",
    "print('--------------------'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee29e3",
   "metadata": {},
   "source": [
    "#### Independent learning in Biased RPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "52c4e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 0\n",
      "Episodes: 1000\n",
      "Episodes: 2000\n",
      "Episodes: 3000\n",
      "Episodes: 4000\n",
      "Episodes: 5000\n",
      "Episodes: 6000\n",
      "Episodes: 7000\n",
      "Episodes: 8000\n",
      "Episodes: 9000\n",
      "Episodes: 10000\n",
      "Episodes: 11000\n",
      "Episodes: 12000\n",
      "Episodes: 13000\n",
      "Episodes: 14000\n",
      "Episodes: 15000\n",
      "Episodes: 16000\n",
      "Episodes: 17000\n",
      "Episodes: 18000\n",
      "Episodes: 19000\n",
      "Episodes: 20000\n",
      "Episodes: 21000\n",
      "Episodes: 22000\n",
      "Episodes: 23000\n",
      "Episodes: 24000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "q_learned_agent1, q_learned_agent2 = train(biased_rps_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e62146",
   "metadata": {},
   "source": [
    "#### Play game against random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a53982b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "[0.25, -0.25]\n",
      "[0.0, 0.0]\n",
      "[-0.05, 0.05]\n",
      "[0.25, -0.25]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0]\n",
      "[0.25, -0.25]\n",
      "[-0.05, 0.05]\n",
      "[0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "play_game(biased_rps_game, q_learned_agent1, random_agent.RandomAgent(player_id=1, num_actions=3))\n",
    "#play_game(biased_rps_game, q_learned_agent1, q_learned_agent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129bf03c",
   "metadata": {},
   "source": [
    "### Dispersion Game\n",
    "-> social dilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fdcc7a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------GAME---------\n",
      "dg()\n",
      "--------------------\n",
      "\n",
      "-------STATE--------\n",
      "Terminal? false\n",
      "Row actions: P1_A P1_B \n",
      "Col actions: P2_A P2_B \n",
      "Utility matrix:\n",
      "-1,-1 1,1 \n",
      "1,1 -1,-1 \n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#configure game\n",
    "row_player_utils = [[-1, 1], [1, -1]]\n",
    "col_player_utils = [[-1, 1], [1, -1]]\n",
    "short_name = 'dg'\n",
    "long_name = 'Dispersion Game'\n",
    "row_names, col_names = ['P1_A', 'P1_B'], ['P2_A', 'P2_B']\n",
    "\n",
    "#initialize game\n",
    "dg_game = pyspiel.create_matrix_game(short_name, long_name, row_names, col_names, row_player_utils, col_player_utils)\n",
    "\n",
    "#display game\n",
    "print('-------GAME---------'+'\\n'+str(dg_game))\n",
    "print('--------------------'+'\\n')\n",
    "\n",
    "#initialize first state of game\n",
    "state = dg_game.new_initial_state()\n",
    "\n",
    "#display state\n",
    "print('-------STATE--------'+'\\n'+str(state))\n",
    "print('--------------------'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df4fa2",
   "metadata": {},
   "source": [
    "#### Independent learning in Dispersion Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eef279bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 0\n",
      "Episodes: 1000\n",
      "Episodes: 2000\n",
      "Episodes: 3000\n",
      "Episodes: 4000\n",
      "Episodes: 5000\n",
      "Episodes: 6000\n",
      "Episodes: 7000\n",
      "Episodes: 8000\n",
      "Episodes: 9000\n",
      "Episodes: 10000\n",
      "Episodes: 11000\n",
      "Episodes: 12000\n",
      "Episodes: 13000\n",
      "Episodes: 14000\n",
      "Episodes: 15000\n",
      "Episodes: 16000\n",
      "Episodes: 17000\n",
      "Episodes: 18000\n",
      "Episodes: 19000\n",
      "Episodes: 20000\n",
      "Episodes: 21000\n",
      "Episodes: 22000\n",
      "Episodes: 23000\n",
      "Episodes: 24000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "q_learned_agent1, q_learned_agent2 = train(dg_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d818de",
   "metadata": {},
   "source": [
    "#### Play game against another agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d98eee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#play_game(dg_game, q_learned_agent1, random_agent.RandomAgent(player_id=1, num_actions=3))\n",
    "play_game(dg_game, q_learned_agent1, q_learned_agent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b0f5e",
   "metadata": {},
   "source": [
    "### Battle of the Sexes\n",
    "-> cooperation game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c3118c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------GAME---------\n",
      "bots()\n",
      "--------------------\n",
      "\n",
      "-------STATE--------\n",
      "Terminal? false\n",
      "Row actions: P1_O P1_M \n",
      "Col actions: P2_O P2_M \n",
      "Utility matrix:\n",
      "3,2 0,0 \n",
      "0,0 2,3 \n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#configure game\n",
    "row_player_utils = [[3, 0], [0, 2]]\n",
    "col_player_utils = [[2, 0], [0, 3]]\n",
    "short_name = 'bots'\n",
    "long_name = 'Battle of the Sexes'\n",
    "row_names, col_names = ['P1_O', 'P1_M'], ['P2_O', 'P2_M']\n",
    "\n",
    "#initialize game\n",
    "bots_game = pyspiel.create_matrix_game(short_name, long_name, row_names, col_names, row_player_utils, col_player_utils)\n",
    "\n",
    "#display game\n",
    "print('-------GAME---------'+'\\n'+str(bots_game))\n",
    "print('--------------------'+'\\n')\n",
    "\n",
    "#initialize first state of game\n",
    "state = bots_game.new_initial_state()\n",
    "\n",
    "#display state\n",
    "print('-------STATE--------'+'\\n'+str(state))\n",
    "print('--------------------'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3978dd18",
   "metadata": {},
   "source": [
    "#### Independent learning in Battle of the Sexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bbe4edb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 0\n",
      "Episodes: 1000\n",
      "Episodes: 2000\n",
      "Episodes: 3000\n",
      "Episodes: 4000\n",
      "Episodes: 5000\n",
      "Episodes: 6000\n",
      "Episodes: 7000\n",
      "Episodes: 8000\n",
      "Episodes: 9000\n",
      "Episodes: 10000\n",
      "Episodes: 11000\n",
      "Episodes: 12000\n",
      "Episodes: 13000\n",
      "Episodes: 14000\n",
      "Episodes: 15000\n",
      "Episodes: 16000\n",
      "Episodes: 17000\n",
      "Episodes: 18000\n",
      "Episodes: 19000\n",
      "Episodes: 20000\n",
      "Episodes: 21000\n",
      "Episodes: 22000\n",
      "Episodes: 23000\n",
      "Episodes: 24000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "q_learned_agent1, q_learned_agent2 = train(bots_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e94607",
   "metadata": {},
   "source": [
    "#### Play game against another agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4bee8e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0]\n",
      "[3.0, 2.0]\n",
      "[0.0, 0.0]\n",
      "[3.0, 2.0]\n",
      "[3.0, 2.0]\n",
      "[3.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "play_game(bots_game, q_learned_agent1, random_agent.RandomAgent(player_id=1, num_actions=3))\n",
    "#play_game(bots_game, q_learned_agent1, q_learned_agent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037886df",
   "metadata": {},
   "source": [
    "### Subsidy Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6fb7d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------GAME---------\n",
      "sg()\n",
      "--------------------\n",
      "\n",
      "-------STATE--------\n",
      "Terminal? false\n",
      "Row actions: P1_S1 P1_S2 \n",
      "Col actions: P2_S1 P2_S2 \n",
      "Utility matrix:\n",
      "10,10 0,11 \n",
      "11,0 12,12 \n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#configure game\n",
    "row_player_utils = [[10, 0], [11, 12]]\n",
    "col_player_utils = [[10, 11], [0, 12]]\n",
    "short_name = 'sg'\n",
    "long_name = 'Subsidy Game'\n",
    "row_names, col_names = ['P1_S1', 'P1_S2'], ['P2_S1', 'P2_S2']\n",
    "\n",
    "#initialize game\n",
    "sg_game = pyspiel.create_matrix_game(short_name, long_name, row_names, col_names, row_player_utils, col_player_utils)\n",
    "\n",
    "#display game\n",
    "print('-------GAME---------'+'\\n'+str(sg_game))\n",
    "print('--------------------'+'\\n')\n",
    "\n",
    "#initialize first state of game\n",
    "state = sg_game.new_initial_state()\n",
    "\n",
    "#display state\n",
    "print('-------STATE--------'+'\\n'+str(state))\n",
    "print('--------------------'+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff24c7",
   "metadata": {},
   "source": [
    "#### Independent learning in Subsidy Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d0660845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 0\n",
      "Episodes: 1000\n",
      "Episodes: 2000\n",
      "Episodes: 3000\n",
      "Episodes: 4000\n",
      "Episodes: 5000\n",
      "Episodes: 6000\n",
      "Episodes: 7000\n",
      "Episodes: 8000\n",
      "Episodes: 9000\n",
      "Episodes: 10000\n",
      "Episodes: 11000\n",
      "Episodes: 12000\n",
      "Episodes: 13000\n",
      "Episodes: 14000\n",
      "Episodes: 15000\n",
      "Episodes: 16000\n",
      "Episodes: 17000\n",
      "Episodes: 18000\n",
      "Episodes: 19000\n",
      "Episodes: 20000\n",
      "Episodes: 21000\n",
      "Episodes: 22000\n",
      "Episodes: 23000\n",
      "Episodes: 24000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "q_learned_agent1, q_learned_agent2 = train(sg_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe31d58",
   "metadata": {},
   "source": [
    "#### Play game against another agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "836e2c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.0, 12.0]\n",
      "[11.0, 0.0]\n",
      "[12.0, 12.0]\n",
      "[12.0, 12.0]\n",
      "[11.0, 0.0]\n",
      "[12.0, 12.0]\n",
      "[11.0, 0.0]\n",
      "[11.0, 0.0]\n",
      "[12.0, 12.0]\n",
      "[11.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "play_game(sg_game, q_learned_agent1, random_agent.RandomAgent(player_id=1, num_actions=3))\n",
    "#play_game(sg_game, q_learned_agent1, q_learned_agent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93bc96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "250dc8700f3acd501be3a96af2484cd0930ae022b5c1b1c81460b46413629d36"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
